% !TeX root = ../tfg.tex
% !TeX encoding = utf8

\chapter{Conclusión}

Concluimos este trabajo habiendo alcanzado los objetivos que nos propusimos al inicio.
Comenzamos revisando las herramientas algebraicas necesarias para comprender la
homología simplicial, estudiando algunos de los principales resultados de este campo
del conocimiento. Esto nos permitió establecer una base sólida desde la cual
explorar en detalle la homología persistente.

Seguidamente, nos adentramos en el ámbito del aprendizaje profundo, con un
enfoque particular en su aplicación a problemas de clasificación de imágenes. Analizamos
las CNNs y las arquitecturas más empleadas en la actualidad, dando un repaso
histórico de los hitos que nos han llevado hasta aquí. Esta exploración no solo reforzó
nuestra comprensión de las técnicas modernas de aprendizaje automático, sino que
también nos preparó para entender cómo estas tecnologías podrían estudiarse
desde el punto de vista de la topología.

Habiendo establecido un marco teórico y técnico robusto, investigamos cómo el TDA,
con un enfoque en la homología persistente, se integra y mejora las capacidades de
las CNNs. Este minucioso análisis nos permitió ahondar en la comprensión de las
CNNs, revelando nuevas perspectivas y metodologías de utilidad para el estudio de
los modelos de aprendizaje profundo.

El núcleo de este trabajo se centró en la implementación y evaluación de un regularizador
topológico diseñado para ajustar la complejidad topológica de los datos procesados
por las CNNs. Los resultados obtenidos demostraron que la inclusión de este
regularizador no solo mejora la precisión de la clasificación, sino que también potencia
la capacidad de transferencia de conocimiento entre diferentes dominios de datos.
Este hallazgo destaca la utilidad del TDA como un puente entre la topología
algebraica y las aplicaciones prácticas en machine learning y visión por
computadora.

Además, el estudio de la transferibilidad de los modelos con regularización topológica
ofreció información sobre cómo las características topológicas ajustadas pueden afectar
positivamente la generalización del modelo más allá de su conjunto de entrenamiento
inicial. Esto se reflejó en una mejora en la clasificación cuando los modelos se
enfrentaron a nuevas etiquetas de los datos, lo cual es de gran interés para la transferencia
de conocimiento con recursos limitados.

Aunque el uso de la regularización topológica ha revelado algunas limitaciones,
el campo del estudio de las CNNs mediante técnicas de TDA es relativamente nuevo
y está demostrando tener un gran potencial. Este trabajo ha establecido una base
sólida para comprender cómo las CNNs afectan la persistencia total y, de manera
más específica, la persistencia total normalizada de los datos. Aún existe un
amplio margen para explorar y descubrir cómo las CNNs transforman la estructura
de los datos, ofreciendo oportunidades para afinar estas técnicas y mejorar la eficacia
de los modelos de aprendizaje profundo.

\chapter{Trabajo futuro}

Nuestro trabajo ha dado un paso más en la comprensión de arquitecturas de aprendizaje
profundo como lo son las CNNs. Dentro del ámbito de estudio de estos modelos
mediante TDA, nuestro trabajo ha ido más allá de los estudios previos y ha profundizado
en cómo afectan distintos componentes y mecanismos en las CNNs a la topología de
los datos. Este estudio en profundidad ha sido posible gracias al empleo de la
persistencia total normalizada, que ha mostrado ser una métrica con una gran capacidad
expresiva en la comprensión de las transformaciones topológicas que realiza una CNN
sobre sus datos.

Estos factores abren una nueva vía de exploración donde poder realizar estudios más
exhaustivos y a distintos niveles de detalle. Empezando por análisis a más alto
nivel, podrían compararse diferentes arquitecturas y conjuntos de datos para ofrecer
conclusiones más robustas sobre cómo afectan a las transformaciones que realizan.
Más aún, sería interesante estudiar cómo afecta cada paso individual del modelo a
la topología de los datos, más allá de considerar las salidas de las
activaciones no lineales.

Por otra parte, el término de regularización topológico ha mostrado ser efectivo
y potencial de mejorar tanto la tasa de clasificación del modelo como su capacidad
de transferibilidad. Sin embargo, su inestabilidad en la elección del hiperparámetro
empleado puede ser un problema y sería interesante encontrar mecanismos más robustos
para elegir correctamente este valor. Otra observación que sería interesante de
analizar es la aparición de artefactos verticales y horizontales en algunos
casos tras la regularización. Además, el regularizador propuesto se ha visto
bastante limitado a la homología persistente en las capas finales del modelo, por
lo que sería interesante explorar mejoras que consideren otras activaciones del modelo
para solucionar el problema.

Como se puede ver, existe un gran margen de mejora en el trabajo propuesto y
numerosas oportunidades para arrojar luz sobre la explicabilidad de modelos de
aprendizaje profundo. El TDA ha mostrado la capacidad de ofrecer información relevante
sobre cómo modifican los datos las CNNs, proponiendo nuevas herramientas que nos
permitan afrontar los nuevos desafíos que nos esperan.

\endinput
%--------------------------------------------------------------------
% FIN DEL CAPÍTULO.
%--------------------------------------------------------------------